---
layout: project
title: Machine Learning Projects
subtitle: "ML projects including Bayes, K-Means, Ensemble Learning"
---
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

These lab projects are for the <b>Introduction to Machine Learning</b> class at <b>Tsinghua University</b>, taught by <a href="http://www.thuir.cn/group/~mzhang/"> Prof. Min Zhang</a>. In total consists of the following lab projects:

<ol>
<li>
<b>Lab 1: Naive Bayes Classifier</b><br>
Implemented a Naive Bayes Classifier with Laplace smoothing and feature design on a real dataset for spam email classification. Evaluated the model using accuracy, precision, recall, and F1 score, with results showcasing over 99% accuracy under optimal configurations.
</li>

<li>
<b>Lab 2: K-Means Clustering Algorithm</b><br>
Designed a K-Means clustering algorithm on the MNIST dataset, analyzing the clustering accuracy and visualizing results with t-SNE. Achieved an accuracy of 79% with 30 clusters, highlighting challenges in cluster initialization and high-dimensional data separation.
<br><img src="/assets/projects/2024_ml-labs/result.png" style="max-width: 100%; height: auto;" alt="result"/><br>
</li>

<li>
<b>Lab 3: Ensemble Learning with Bagging and AdaBoost</b><br>
Developed ensemble models combining Bagging and AdaBoost with SVM and Decision Tree classifiers to predict product review scores. Compared the models' performance using MAE, MSE, and RMSE, showing mixed results with Bagging SVM performing slightly better, while AdaBoost exhibited limited effectiveness for this dataset.
</li>
</ol>

Check out the code implementation and report on <a href="https://github.com/kalyakornA/2024S-ML">Github</a>